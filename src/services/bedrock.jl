# This file is auto-generated by AWSMetadata.jl
using AWS
using AWS.AWSServices: bedrock
using AWS.Compat
using AWS.UUIDs

"""
    batch_delete_evaluation_job(job_identifiers)
    batch_delete_evaluation_job(job_identifiers, params::Dict{String,<:Any})

Creates a batch deletion job. A model evaluation job can only be deleted if it has
following status FAILED, COMPLETED, and STOPPED. You can request up to 25 model evaluation
jobs be deleted in a single request.

# Arguments
- `job_identifiers`: An array of model evaluation job ARNs to be deleted.

"""
batch_delete_evaluation_job(
    jobIdentifiers; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "POST",
    "/evaluation-jobs/batch-delete",
    Dict{String,Any}("jobIdentifiers" => jobIdentifiers);
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function batch_delete_evaluation_job(
    jobIdentifiers,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/evaluation-jobs/batch-delete",
        Dict{String,Any}(
            mergewith(_merge, Dict{String,Any}("jobIdentifiers" => jobIdentifiers), params)
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    create_evaluation_job(evaluation_config, inference_config, job_name, output_data_config, role_arn)
    create_evaluation_job(evaluation_config, inference_config, job_name, output_data_config, role_arn, params::Dict{String,<:Any})

API operation for creating and managing Amazon Bedrock automatic model evaluation jobs and
model evaluation jobs that use human workers. To learn more about the requirements for
creating a model evaluation job see, Model evaluation.

# Arguments
- `evaluation_config`: Specifies whether the model evaluation job is automatic or uses
  human worker.
- `inference_config`: Specify the models you want to use in your model evaluation job.
  Automatic model evaluation jobs support a single model, and model evaluation job that use
  human workers support two models.
- `job_name`: The name of the model evaluation job. Model evaluation job names must unique
  with your AWS account, and your account's AWS region.
- `output_data_config`: An object that defines where the results of model evaluation job
  will be saved in Amazon S3.
- `role_arn`: The Amazon Resource Name (ARN) of an IAM service role that Amazon Bedrock can
  assume to perform tasks on your behalf. The service role must have Amazon Bedrock as the
  service principal, and provide access to any Amazon S3 buckets specified in the
  EvaluationConfig object. To pass this role to Amazon Bedrock, the caller of this API must
  have the iam:PassRole permission. To learn more about the required permissions, see
  Required permissions.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"clientRequestToken"`: A unique, case-sensitive identifier to ensure that the API
  request completes no more than one time. If this token matches a previous request, Amazon
  Bedrock ignores the request, but does not return an error. For more information, see
  Ensuring idempotency.
- `"customerEncryptionKeyId"`: Specify your customer managed key ARN that will be used to
  encrypt your model evaluation job.
- `"jobDescription"`: A description of the model evaluation job.
- `"jobTags"`: Tags to attach to the model evaluation job.
"""
create_evaluation_job(
    evaluationConfig,
    inferenceConfig,
    jobName,
    outputDataConfig,
    roleArn;
    aws_config::AbstractAWSConfig=current_aws_config(),
) = bedrock(
    "POST",
    "/evaluation-jobs",
    Dict{String,Any}(
        "evaluationConfig" => evaluationConfig,
        "inferenceConfig" => inferenceConfig,
        "jobName" => jobName,
        "outputDataConfig" => outputDataConfig,
        "roleArn" => roleArn,
        "clientRequestToken" => string(uuid4()),
    );
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function create_evaluation_job(
    evaluationConfig,
    inferenceConfig,
    jobName,
    outputDataConfig,
    roleArn,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/evaluation-jobs",
        Dict{String,Any}(
            mergewith(
                _merge,
                Dict{String,Any}(
                    "evaluationConfig" => evaluationConfig,
                    "inferenceConfig" => inferenceConfig,
                    "jobName" => jobName,
                    "outputDataConfig" => outputDataConfig,
                    "roleArn" => roleArn,
                    "clientRequestToken" => string(uuid4()),
                ),
                params,
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    create_guardrail(blocked_input_messaging, blocked_outputs_messaging, name)
    create_guardrail(blocked_input_messaging, blocked_outputs_messaging, name, params::Dict{String,<:Any})

Creates a guardrail to block topics and to implement safeguards for your generative AI
applications. You can configure the following policies in a guardrail to avoid undesirable
and harmful content, filter out denied topics and words, and remove sensitive information
for privacy protection.    Content filters - Adjust filter strengths to block input prompts
or model responses containing harmful content.    Denied topics - Define a set of topics
that are undesirable in the context of your application. These topics will be blocked if
detected in user queries or model responses.    Word filters - Configure filters to block
undesirable words, phrases, and profanity. Such words can include offensive terms,
competitor names etc.    Sensitive information filters - Block or mask sensitive
information such as personally identifiable information (PII) or custom regex in user
inputs and model responses.   In addition to the above policies, you can also configure the
messages to be returned to the user if a user input or model response is in violation of
the policies defined in the guardrail. For more information, see Guardrails for Amazon
Bedrock in the Amazon Bedrock User Guide.

# Arguments
- `blocked_input_messaging`: The message to return when the guardrail blocks a prompt.
- `blocked_outputs_messaging`: The message to return when the guardrail blocks a model
  response.
- `name`: The name to give the guardrail.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"clientRequestToken"`: A unique, case-sensitive identifier to ensure that the API
  request completes no more than once. If this token matches a previous request, Amazon
  Bedrock ignores the request, but does not return an error. For more information, see
  Ensuring idempotency in the Amazon S3 User Guide.
- `"contentPolicyConfig"`: The content filter policies to configure for the guardrail.
- `"contextualGroundingPolicyConfig"`: The contextual grounding policy configuration used
  to create a guardrail.
- `"description"`: A description of the guardrail.
- `"kmsKeyId"`: The ARN of the KMS key that you use to encrypt the guardrail.
- `"sensitiveInformationPolicyConfig"`: The sensitive information policy to configure for
  the guardrail.
- `"tags"`: The tags that you want to attach to the guardrail.
- `"topicPolicyConfig"`: The topic policies to configure for the guardrail.
- `"wordPolicyConfig"`: The word policy you configure for the guardrail.
"""
create_guardrail(
    blockedInputMessaging,
    blockedOutputsMessaging,
    name;
    aws_config::AbstractAWSConfig=current_aws_config(),
) = bedrock(
    "POST",
    "/guardrails",
    Dict{String,Any}(
        "blockedInputMessaging" => blockedInputMessaging,
        "blockedOutputsMessaging" => blockedOutputsMessaging,
        "name" => name,
        "clientRequestToken" => string(uuid4()),
    );
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function create_guardrail(
    blockedInputMessaging,
    blockedOutputsMessaging,
    name,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/guardrails",
        Dict{String,Any}(
            mergewith(
                _merge,
                Dict{String,Any}(
                    "blockedInputMessaging" => blockedInputMessaging,
                    "blockedOutputsMessaging" => blockedOutputsMessaging,
                    "name" => name,
                    "clientRequestToken" => string(uuid4()),
                ),
                params,
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    create_guardrail_version(guardrail_identifier)
    create_guardrail_version(guardrail_identifier, params::Dict{String,<:Any})

Creates a version of the guardrail. Use this API to create a snapshot of the guardrail when
you are satisfied with a configuration, or to compare the configuration with another
version.

# Arguments
- `guardrail_identifier`: The unique identifier of the guardrail. This can be an ID or the
  ARN.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"clientRequestToken"`: A unique, case-sensitive identifier to ensure that the API
  request completes no more than once. If this token matches a previous request, Amazon
  Bedrock ignores the request, but does not return an error. For more information, see
  Ensuring idempotency in the Amazon S3 User Guide.
- `"description"`: A description of the guardrail version.
"""
create_guardrail_version(
    guardrailIdentifier; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "POST",
    "/guardrails/$(guardrailIdentifier)",
    Dict{String,Any}("clientRequestToken" => string(uuid4()));
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function create_guardrail_version(
    guardrailIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/guardrails/$(guardrailIdentifier)",
        Dict{String,Any}(
            mergewith(
                _merge, Dict{String,Any}("clientRequestToken" => string(uuid4())), params
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    create_model_copy_job(source_model_arn, target_model_name)
    create_model_copy_job(source_model_arn, target_model_name, params::Dict{String,<:Any})

Copies a model to another region so that it can be used there. For more information, see
Copy models to be used in other regions in the Amazon Bedrock User Guide.

# Arguments
- `source_model_arn`: The Amazon Resource Name (ARN) of the model to be copied.
- `target_model_name`: A name for the copied model.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"clientRequestToken"`: A unique, case-sensitive identifier to ensure that the API
  request completes no more than one time. If this token matches a previous request, Amazon
  Bedrock ignores the request, but does not return an error. For more information, see
  Ensuring idempotency.
- `"modelKmsKeyId"`: The ARN of the KMS key that you use to encrypt the model copy.
- `"targetModelTags"`: Tags to associate with the target model. For more information, see
  Tag resources in the Amazon Bedrock User Guide.
"""
create_model_copy_job(
    sourceModelArn, targetModelName; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "POST",
    "/model-copy-jobs",
    Dict{String,Any}(
        "sourceModelArn" => sourceModelArn,
        "targetModelName" => targetModelName,
        "clientRequestToken" => string(uuid4()),
    );
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function create_model_copy_job(
    sourceModelArn,
    targetModelName,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/model-copy-jobs",
        Dict{String,Any}(
            mergewith(
                _merge,
                Dict{String,Any}(
                    "sourceModelArn" => sourceModelArn,
                    "targetModelName" => targetModelName,
                    "clientRequestToken" => string(uuid4()),
                ),
                params,
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    create_model_customization_job(base_model_identifier, custom_model_name, hyper_parameters, job_name, output_data_config, role_arn, training_data_config)
    create_model_customization_job(base_model_identifier, custom_model_name, hyper_parameters, job_name, output_data_config, role_arn, training_data_config, params::Dict{String,<:Any})

Creates a fine-tuning job to customize a base model. You specify the base foundation model
and the location of the training data. After the model-customization job completes
successfully, your custom model resource will be ready to use. Amazon Bedrock returns
validation loss metrics and output generations after the job completes.  For information on
the format of training and validation data, see Prepare the datasets.  Model-customization
jobs are asynchronous and the completion time depends on the base model and the
training/validation data size. To monitor a job, use the GetModelCustomizationJob operation
to retrieve the job status. For more information, see Custom models in the Amazon Bedrock
User Guide.

# Arguments
- `base_model_identifier`: Name of the base model.
- `custom_model_name`: A name for the resulting custom model.
- `hyper_parameters`: Parameters related to tuning the model. For details on the format for
  different models, see Custom model hyperparameters.
- `job_name`: A name for the fine-tuning job.
- `output_data_config`: S3 location for the output data.
- `role_arn`: The Amazon Resource Name (ARN) of an IAM service role that Amazon Bedrock can
  assume to perform tasks on your behalf. For example, during model training, Amazon Bedrock
  needs your permission to read input data from an S3 bucket, write model artifacts to an S3
  bucket. To pass this role to Amazon Bedrock, the caller of this API must have the
  iam:PassRole permission.
- `training_data_config`: Information about the training dataset.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"clientRequestToken"`: A unique, case-sensitive identifier to ensure that the API
  request completes no more than one time. If this token matches a previous request, Amazon
  Bedrock ignores the request, but does not return an error. For more information, see
  Ensuring idempotency.
- `"customModelKmsKeyId"`: The custom model is encrypted at rest using this key.
- `"customModelTags"`: Tags to attach to the resulting custom model.
- `"customizationType"`: The customization type.
- `"jobTags"`: Tags to attach to the job.
- `"validationDataConfig"`: Information about the validation dataset.
- `"vpcConfig"`: VPC configuration (optional). Configuration parameters for the private
  Virtual Private Cloud (VPC) that contains the resources you are using for this job.
"""
create_model_customization_job(
    baseModelIdentifier,
    customModelName,
    hyperParameters,
    jobName,
    outputDataConfig,
    roleArn,
    trainingDataConfig;
    aws_config::AbstractAWSConfig=current_aws_config(),
) = bedrock(
    "POST",
    "/model-customization-jobs",
    Dict{String,Any}(
        "baseModelIdentifier" => baseModelIdentifier,
        "customModelName" => customModelName,
        "hyperParameters" => hyperParameters,
        "jobName" => jobName,
        "outputDataConfig" => outputDataConfig,
        "roleArn" => roleArn,
        "trainingDataConfig" => trainingDataConfig,
        "clientRequestToken" => string(uuid4()),
    );
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function create_model_customization_job(
    baseModelIdentifier,
    customModelName,
    hyperParameters,
    jobName,
    outputDataConfig,
    roleArn,
    trainingDataConfig,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/model-customization-jobs",
        Dict{String,Any}(
            mergewith(
                _merge,
                Dict{String,Any}(
                    "baseModelIdentifier" => baseModelIdentifier,
                    "customModelName" => customModelName,
                    "hyperParameters" => hyperParameters,
                    "jobName" => jobName,
                    "outputDataConfig" => outputDataConfig,
                    "roleArn" => roleArn,
                    "trainingDataConfig" => trainingDataConfig,
                    "clientRequestToken" => string(uuid4()),
                ),
                params,
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    create_model_import_job(imported_model_name, job_name, model_data_source, role_arn)
    create_model_import_job(imported_model_name, job_name, model_data_source, role_arn, params::Dict{String,<:Any})

Creates a model import job to import model that you have customized in other environments,
such as Amazon SageMaker. For more information, see Import a customized model

# Arguments
- `imported_model_name`: The name of the imported model.
- `job_name`: The name of the import job.
- `model_data_source`: The data source for the imported model.
- `role_arn`: The Amazon Resource Name (ARN) of the model import job.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"clientRequestToken"`: A unique, case-sensitive identifier to ensure that the API
  request completes no more than one time. If this token matches a previous request, Amazon
  Bedrock ignores the request, but does not return an error. For more information, see
  Ensuring idempotency.
- `"importedModelKmsKeyId"`: The imported model is encrypted at rest using this key.
- `"importedModelTags"`: Tags to attach to the imported model.
- `"jobTags"`: Tags to attach to this import job.
- `"vpcConfig"`: VPC configuration parameters for the private Virtual Private Cloud (VPC)
  that contains the resources you are using for the import job.
"""
create_model_import_job(
    importedModelName,
    jobName,
    modelDataSource,
    roleArn;
    aws_config::AbstractAWSConfig=current_aws_config(),
) = bedrock(
    "POST",
    "/model-import-jobs",
    Dict{String,Any}(
        "importedModelName" => importedModelName,
        "jobName" => jobName,
        "modelDataSource" => modelDataSource,
        "roleArn" => roleArn,
    );
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function create_model_import_job(
    importedModelName,
    jobName,
    modelDataSource,
    roleArn,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/model-import-jobs",
        Dict{String,Any}(
            mergewith(
                _merge,
                Dict{String,Any}(
                    "importedModelName" => importedModelName,
                    "jobName" => jobName,
                    "modelDataSource" => modelDataSource,
                    "roleArn" => roleArn,
                ),
                params,
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    create_model_invocation_job(input_data_config, job_name, model_id, output_data_config, role_arn)
    create_model_invocation_job(input_data_config, job_name, model_id, output_data_config, role_arn, params::Dict{String,<:Any})

Creates a batch inference job to invoke a model on multiple prompts. Format your data
according to Format your inference data and upload it to an Amazon S3 bucket. For more
information, see Process multiple prompts with batch inference. The response returns a
jobArn that you can use to stop or get details about the job.

# Arguments
- `input_data_config`: Details about the location of the input to the batch inference job.
- `job_name`: A name to give the batch inference job.
- `model_id`: The unique identifier of the foundation model to use for the batch inference
  job.
- `output_data_config`: Details about the location of the output of the batch inference job.
- `role_arn`: The Amazon Resource Name (ARN) of the service role with permissions to carry
  out and manage batch inference. You can use the console to create a default service role or
  follow the steps at Create a service role for batch inference.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"clientRequestToken"`: A unique, case-sensitive identifier to ensure that the API
  request completes no more than one time. If this token matches a previous request, Amazon
  Bedrock ignores the request, but does not return an error. For more information, see
  Ensuring idempotency.
- `"tags"`: Any tags to associate with the batch inference job. For more information, see
  Tagging Amazon Bedrock resources.
- `"timeoutDurationInHours"`: The number of hours after which to force the batch inference
  job to time out.
"""
create_model_invocation_job(
    inputDataConfig,
    jobName,
    modelId,
    outputDataConfig,
    roleArn;
    aws_config::AbstractAWSConfig=current_aws_config(),
) = bedrock(
    "POST",
    "/model-invocation-job",
    Dict{String,Any}(
        "inputDataConfig" => inputDataConfig,
        "jobName" => jobName,
        "modelId" => modelId,
        "outputDataConfig" => outputDataConfig,
        "roleArn" => roleArn,
        "clientRequestToken" => string(uuid4()),
    );
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function create_model_invocation_job(
    inputDataConfig,
    jobName,
    modelId,
    outputDataConfig,
    roleArn,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/model-invocation-job",
        Dict{String,Any}(
            mergewith(
                _merge,
                Dict{String,Any}(
                    "inputDataConfig" => inputDataConfig,
                    "jobName" => jobName,
                    "modelId" => modelId,
                    "outputDataConfig" => outputDataConfig,
                    "roleArn" => roleArn,
                    "clientRequestToken" => string(uuid4()),
                ),
                params,
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    create_provisioned_model_throughput(model_id, model_units, provisioned_model_name)
    create_provisioned_model_throughput(model_id, model_units, provisioned_model_name, params::Dict{String,<:Any})

Creates dedicated throughput for a base or custom model with the model units and for the
duration that you specify. For pricing details, see Amazon Bedrock Pricing. For more
information, see Provisioned Throughput in the Amazon Bedrock User Guide.

# Arguments
- `model_id`: The Amazon Resource Name (ARN) or name of the model to associate with this
  Provisioned Throughput. For a list of models for which you can purchase Provisioned
  Throughput, see Amazon Bedrock model IDs for purchasing Provisioned Throughput in the
  Amazon Bedrock User Guide.
- `model_units`: Number of model units to allocate. A model unit delivers a specific
  throughput level for the specified model. The throughput level of a model unit specifies
  the total number of input and output tokens that it can process and generate within a span
  of one minute. By default, your account has no model units for purchasing Provisioned
  Throughputs with commitment. You must first visit the Amazon Web Services support center to
  request MUs. For model unit quotas, see Provisioned Throughput quotas in the Amazon Bedrock
  User Guide. For more information about what an MU specifies, contact your Amazon Web
  Services account manager.
- `provisioned_model_name`: The name for this Provisioned Throughput.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"clientRequestToken"`: A unique, case-sensitive identifier to ensure that the API
  request completes no more than one time. If this token matches a previous request, Amazon
  Bedrock ignores the request, but does not return an error. For more information, see
  Ensuring idempotency in the Amazon S3 User Guide.
- `"commitmentDuration"`: The commitment duration requested for the Provisioned Throughput.
  Billing occurs hourly and is discounted for longer commitment terms. To request a no-commit
  Provisioned Throughput, omit this field. Custom models support all levels of commitment. To
  see which base models support no commitment, see Supported regions and models for
  Provisioned Throughput in the Amazon Bedrock User Guide
- `"tags"`: Tags to associate with this Provisioned Throughput.
"""
create_provisioned_model_throughput(
    modelId,
    modelUnits,
    provisionedModelName;
    aws_config::AbstractAWSConfig=current_aws_config(),
) = bedrock(
    "POST",
    "/provisioned-model-throughput",
    Dict{String,Any}(
        "modelId" => modelId,
        "modelUnits" => modelUnits,
        "provisionedModelName" => provisionedModelName,
        "clientRequestToken" => string(uuid4()),
    );
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function create_provisioned_model_throughput(
    modelId,
    modelUnits,
    provisionedModelName,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/provisioned-model-throughput",
        Dict{String,Any}(
            mergewith(
                _merge,
                Dict{String,Any}(
                    "modelId" => modelId,
                    "modelUnits" => modelUnits,
                    "provisionedModelName" => provisionedModelName,
                    "clientRequestToken" => string(uuid4()),
                ),
                params,
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    delete_custom_model(model_identifier)
    delete_custom_model(model_identifier, params::Dict{String,<:Any})

Deletes a custom model that you created earlier. For more information, see Custom models in
the Amazon Bedrock User Guide.

# Arguments
- `model_identifier`: Name of the model to delete.

"""
delete_custom_model(modelIdentifier; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "DELETE",
        "/custom-models/$(modelIdentifier)";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function delete_custom_model(
    modelIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "DELETE",
        "/custom-models/$(modelIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    delete_guardrail(guardrail_identifier)
    delete_guardrail(guardrail_identifier, params::Dict{String,<:Any})

Deletes a guardrail.   To delete a guardrail, only specify the ARN of the guardrail in the
guardrailIdentifier field. If you delete a guardrail, all of its versions will be deleted.
 To delete a version of a guardrail, specify the ARN of the guardrail in the
guardrailIdentifier field and the version in the guardrailVersion field.

# Arguments
- `guardrail_identifier`: The unique identifier of the guardrail. This can be an ID or the
  ARN.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"guardrailVersion"`: The version of the guardrail.
"""
delete_guardrail(guardrailIdentifier; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "DELETE",
        "/guardrails/$(guardrailIdentifier)";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function delete_guardrail(
    guardrailIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "DELETE",
        "/guardrails/$(guardrailIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    delete_imported_model(model_identifier)
    delete_imported_model(model_identifier, params::Dict{String,<:Any})

Deletes a custom model that you imported earlier. For more information, see Import a
customized model in the Amazon Bedrock User Guide.

# Arguments
- `model_identifier`: Name of the imported model to delete.

"""
delete_imported_model(modelIdentifier; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "DELETE",
        "/imported-models/$(modelIdentifier)";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function delete_imported_model(
    modelIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "DELETE",
        "/imported-models/$(modelIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    delete_model_invocation_logging_configuration()
    delete_model_invocation_logging_configuration(params::Dict{String,<:Any})

Delete the invocation logging.

"""
delete_model_invocation_logging_configuration(;
    aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "DELETE",
    "/logging/modelinvocations";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function delete_model_invocation_logging_configuration(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "DELETE",
        "/logging/modelinvocations",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    delete_provisioned_model_throughput(provisioned_model_id)
    delete_provisioned_model_throughput(provisioned_model_id, params::Dict{String,<:Any})

Deletes a Provisioned Throughput. You can't delete a Provisioned Throughput before the
commitment term is over. For more information, see Provisioned Throughput in the Amazon
Bedrock User Guide.

# Arguments
- `provisioned_model_id`: The Amazon Resource Name (ARN) or name of the Provisioned
  Throughput.

"""
delete_provisioned_model_throughput(
    provisionedModelId; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "DELETE",
    "/provisioned-model-throughput/$(provisionedModelId)";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function delete_provisioned_model_throughput(
    provisionedModelId,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "DELETE",
        "/provisioned-model-throughput/$(provisionedModelId)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_custom_model(model_identifier)
    get_custom_model(model_identifier, params::Dict{String,<:Any})

Get the properties associated with a Amazon Bedrock custom model that you have created.For
more information, see Custom models in the Amazon Bedrock User Guide.

# Arguments
- `model_identifier`: Name or Amazon Resource Name (ARN) of the custom model.

"""
get_custom_model(modelIdentifier; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "GET",
        "/custom-models/$(modelIdentifier)";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function get_custom_model(
    modelIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "GET",
        "/custom-models/$(modelIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_evaluation_job(job_identifier)
    get_evaluation_job(job_identifier, params::Dict{String,<:Any})

Retrieves the properties associated with a model evaluation job, including the status of
the job. For more information, see Model evaluation.

# Arguments
- `job_identifier`: The Amazon Resource Name (ARN) of the model evaluation job.

"""
get_evaluation_job(jobIdentifier; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "GET",
        "/evaluation-jobs/$(jobIdentifier)";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function get_evaluation_job(
    jobIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "GET",
        "/evaluation-jobs/$(jobIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_foundation_model(model_identifier)
    get_foundation_model(model_identifier, params::Dict{String,<:Any})

Get details about a Amazon Bedrock foundation model.

# Arguments
- `model_identifier`: The model identifier.

"""
get_foundation_model(modelIdentifier; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "GET",
        "/foundation-models/$(modelIdentifier)";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function get_foundation_model(
    modelIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "GET",
        "/foundation-models/$(modelIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_guardrail(guardrail_identifier)
    get_guardrail(guardrail_identifier, params::Dict{String,<:Any})

Gets details about a guardrail. If you don't specify a version, the response returns
details for the DRAFT version.

# Arguments
- `guardrail_identifier`: The unique identifier of the guardrail for which to get details.
  This can be an ID or the ARN.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"guardrailVersion"`: The version of the guardrail for which to get details. If you don't
  specify a version, the response returns details for the DRAFT version.
"""
get_guardrail(guardrailIdentifier; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "GET",
        "/guardrails/$(guardrailIdentifier)";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function get_guardrail(
    guardrailIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "GET",
        "/guardrails/$(guardrailIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_imported_model(model_identifier)
    get_imported_model(model_identifier, params::Dict{String,<:Any})

Gets properties associated with a customized model you imported.

# Arguments
- `model_identifier`: Name or Amazon Resource Name (ARN) of the imported model.

"""
get_imported_model(modelIdentifier; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "GET",
        "/imported-models/$(modelIdentifier)";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function get_imported_model(
    modelIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "GET",
        "/imported-models/$(modelIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_inference_profile(inference_profile_identifier)
    get_inference_profile(inference_profile_identifier, params::Dict{String,<:Any})

Gets information about an inference profile. For more information, see the Amazon Bedrock
User Guide.

# Arguments
- `inference_profile_identifier`: The unique identifier of the inference profile.

"""
get_inference_profile(
    inferenceProfileIdentifier; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "GET",
    "/inference-profiles/$(inferenceProfileIdentifier)";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function get_inference_profile(
    inferenceProfileIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "GET",
        "/inference-profiles/$(inferenceProfileIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_model_copy_job(job_arn)
    get_model_copy_job(job_arn, params::Dict{String,<:Any})

Retrieves information about a model copy job. For more information, see Copy models to be
used in other regions in the Amazon Bedrock User Guide.

# Arguments
- `job_arn`: The Amazon Resource Name (ARN) of the model copy job.

"""
get_model_copy_job(jobArn; aws_config::AbstractAWSConfig=current_aws_config()) = bedrock(
    "GET",
    "/model-copy-jobs/$(jobArn)";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function get_model_copy_job(
    jobArn, params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/model-copy-jobs/$(jobArn)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_model_customization_job(job_identifier)
    get_model_customization_job(job_identifier, params::Dict{String,<:Any})

Retrieves the properties associated with a model-customization job, including the status of
the job. For more information, see Custom models in the Amazon Bedrock User Guide.

# Arguments
- `job_identifier`: Identifier for the customization job.

"""
get_model_customization_job(
    jobIdentifier; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "GET",
    "/model-customization-jobs/$(jobIdentifier)";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function get_model_customization_job(
    jobIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "GET",
        "/model-customization-jobs/$(jobIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_model_import_job(job_identifier)
    get_model_import_job(job_identifier, params::Dict{String,<:Any})

Retrieves the properties associated with import model job, including the status of the job.
For more information, see Import a customized model in the Amazon Bedrock User Guide.

# Arguments
- `job_identifier`: The identifier of the import job.

"""
get_model_import_job(jobIdentifier; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "GET",
        "/model-import-jobs/$(jobIdentifier)";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function get_model_import_job(
    jobIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "GET",
        "/model-import-jobs/$(jobIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_model_invocation_job(job_identifier)
    get_model_invocation_job(job_identifier, params::Dict{String,<:Any})

Gets details about a batch inference job. For more information, see View details about a
batch inference job

# Arguments
- `job_identifier`: The Amazon Resource Name (ARN) of the batch inference job.

"""
get_model_invocation_job(
    jobIdentifier; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "GET",
    "/model-invocation-job/$(jobIdentifier)";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function get_model_invocation_job(
    jobIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "GET",
        "/model-invocation-job/$(jobIdentifier)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_model_invocation_logging_configuration()
    get_model_invocation_logging_configuration(params::Dict{String,<:Any})

Get the current configuration values for model invocation logging.

"""
get_model_invocation_logging_configuration(;
    aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "GET",
    "/logging/modelinvocations";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function get_model_invocation_logging_configuration(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/logging/modelinvocations",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    get_provisioned_model_throughput(provisioned_model_id)
    get_provisioned_model_throughput(provisioned_model_id, params::Dict{String,<:Any})

Returns details for a Provisioned Throughput. For more information, see Provisioned
Throughput in the Amazon Bedrock User Guide.

# Arguments
- `provisioned_model_id`: The Amazon Resource Name (ARN) or name of the Provisioned
  Throughput.

"""
get_provisioned_model_throughput(
    provisionedModelId; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "GET",
    "/provisioned-model-throughput/$(provisionedModelId)";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function get_provisioned_model_throughput(
    provisionedModelId,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "GET",
        "/provisioned-model-throughput/$(provisionedModelId)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_custom_models()
    list_custom_models(params::Dict{String,<:Any})

Returns a list of the custom models that you have created with the
CreateModelCustomizationJob operation. For more information, see Custom models in the
Amazon Bedrock User Guide.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"baseModelArnEquals"`: Return custom models only if the base model Amazon Resource Name
  (ARN) matches this parameter.
- `"creationTimeAfter"`: Return custom models created after the specified time.
- `"creationTimeBefore"`: Return custom models created before the specified time.
- `"foundationModelArnEquals"`: Return custom models only if the foundation model Amazon
  Resource Name (ARN) matches this parameter.
- `"isOwned"`: Return custom models depending on if the current account owns them (true) or
  if they were shared with the current account (false).
- `"maxResults"`: The maximum number of results to return in the response. If the total
  number of results is greater than this value, use the token returned in the response in the
  nextToken field when making another request to return the next batch of results.
- `"nameContains"`: Return custom models only if the job name contains these characters.
- `"nextToken"`: If the total number of results is greater than the maxResults value
  provided in the request, enter the token returned in the nextToken field in the response in
  this field to return the next batch of results.
- `"sortBy"`: The field to sort by in the returned list of models.
- `"sortOrder"`: The sort order of the results.
"""
list_custom_models(; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock("GET", "/custom-models"; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
function list_custom_models(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/custom-models",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_evaluation_jobs()
    list_evaluation_jobs(params::Dict{String,<:Any})

Lists model evaluation jobs.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"creationTimeAfter"`: A filter that includes model evaluation jobs created after the
  time specified.
- `"creationTimeBefore"`: A filter that includes model evaluation jobs created prior to the
  time specified.
- `"maxResults"`: The maximum number of results to return.
- `"nameContains"`: Query parameter string for model evaluation job names.
- `"nextToken"`: Continuation token from the previous response, for Amazon Bedrock to list
  the next set of results.
- `"sortBy"`: Allows you to sort model evaluation jobs by when they were created.
- `"sortOrder"`: How you want the order of jobs sorted.
- `"statusEquals"`: Only return jobs where the status condition is met.
"""
list_evaluation_jobs(; aws_config::AbstractAWSConfig=current_aws_config()) = bedrock(
    "GET", "/evaluation-jobs"; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET
)
function list_evaluation_jobs(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/evaluation-jobs",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_foundation_models()
    list_foundation_models(params::Dict{String,<:Any})

Lists Amazon Bedrock foundation models that you can use. You can filter the results with
the request parameters. For more information, see Foundation models in the Amazon Bedrock
User Guide.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"byCustomizationType"`: Return models that support the customization type that you
  specify. For more information, see Custom models in the Amazon Bedrock User Guide.
- `"byInferenceType"`: Return models that support the inference type that you specify. For
  more information, see Provisioned Throughput in the Amazon Bedrock User Guide.
- `"byOutputModality"`: Return models that support the output modality that you specify.
- `"byProvider"`: Return models belonging to the model provider that you specify.
"""
list_foundation_models(; aws_config::AbstractAWSConfig=current_aws_config()) = bedrock(
    "GET", "/foundation-models"; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET
)
function list_foundation_models(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/foundation-models",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_guardrails()
    list_guardrails(params::Dict{String,<:Any})

Lists details about all the guardrails in an account. To list the DRAFT version of all your
guardrails, don't specify the guardrailIdentifier field. To list all versions of a
guardrail, specify the ARN of the guardrail in the guardrailIdentifier field. You can set
the maximum number of results to return in a response in the maxResults field. If there are
more results than the number you set, the response returns a nextToken that you can send in
another ListGuardrails request to see the next batch of results.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"guardrailIdentifier"`: The unique identifier of the guardrail. This can be an ID or the
  ARN.
- `"maxResults"`: The maximum number of results to return in the response.
- `"nextToken"`: If there are more results than were returned in the response, the response
  returns a nextToken that you can send in another ListGuardrails request to see the next
  batch of results.
"""
list_guardrails(; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock("GET", "/guardrails"; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
function list_guardrails(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET", "/guardrails", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET
    )
end

"""
    list_imported_models()
    list_imported_models(params::Dict{String,<:Any})

Returns a list of models you've imported. You can filter the results to return based on one
or more criteria. For more information, see Import a customized model in the Amazon Bedrock
User Guide.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"creationTimeAfter"`: Return imported models that were created after the specified time.
- `"creationTimeBefore"`: Return imported models that created before the specified time.
- `"maxResults"`: The maximum number of results to return in the response. If the total
  number of results is greater than this value, use the token returned in the response in the
  nextToken field when making another request to return the next batch of results.
- `"nameContains"`: Return imported models only if the model name contains these characters.
- `"nextToken"`: If the total number of results is greater than the maxResults value
  provided in the request, enter the token returned in the nextToken field in the response in
  this field to return the next batch of results.
- `"sortBy"`: The field to sort by in the returned list of imported models.
- `"sortOrder"`: Specifies whetehr to sort the results in ascending or descending order.
"""
list_imported_models(; aws_config::AbstractAWSConfig=current_aws_config()) = bedrock(
    "GET", "/imported-models"; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET
)
function list_imported_models(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/imported-models",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_inference_profiles()
    list_inference_profiles(params::Dict{String,<:Any})

Returns a list of inference profiles that you can use.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"maxResults"`: The maximum number of results to return in the response. If the total
  number of results is greater than this value, use the token returned in the response in the
  nextToken field when making another request to return the next batch of results.
- `"nextToken"`: If the total number of results is greater than the maxResults value
  provided in the request, enter the token returned in the nextToken field in the response in
  this field to return the next batch of results.
"""
list_inference_profiles(; aws_config::AbstractAWSConfig=current_aws_config()) = bedrock(
    "GET", "/inference-profiles"; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET
)
function list_inference_profiles(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/inference-profiles",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_model_copy_jobs()
    list_model_copy_jobs(params::Dict{String,<:Any})

Returns a list of model copy jobs that you have submitted. You can filter the jobs to
return based on one or more criteria. For more information, see Copy models to be used in
other regions in the Amazon Bedrock User Guide.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"creationTimeAfter"`: Filters for model copy jobs created after the specified time.
- `"creationTimeBefore"`: Filters for model copy jobs created before the specified time.
- `"maxResults"`: The maximum number of results to return in the response. If the total
  number of results is greater than this value, use the token returned in the response in the
  nextToken field when making another request to return the next batch of results.
- `"nextToken"`: If the total number of results is greater than the maxResults value
  provided in the request, enter the token returned in the nextToken field in the response in
  this field to return the next batch of results.
- `"outputModelNameContains"`: Filters for model copy jobs in which the name of the copied
  model contains the string that you specify.
- `"sortBy"`: The field to sort by in the returned list of model copy jobs.
- `"sortOrder"`: Specifies whether to sort the results in ascending or descending order.
- `"sourceAccountEquals"`: Filters for model copy jobs in which the account that the source
  model belongs to is equal to the value that you specify.
- `"sourceModelArnEquals"`: Filters for model copy jobs in which the Amazon Resource Name
  (ARN) of the source model to is equal to the value that you specify.
- `"statusEquals"`: Filters for model copy jobs whose status matches the value that you
  specify.
"""
list_model_copy_jobs(; aws_config::AbstractAWSConfig=current_aws_config()) = bedrock(
    "GET", "/model-copy-jobs"; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET
)
function list_model_copy_jobs(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/model-copy-jobs",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_model_customization_jobs()
    list_model_customization_jobs(params::Dict{String,<:Any})

Returns a list of model customization jobs that you have submitted. You can filter the jobs
to return based on one or more criteria. For more information, see Custom models in the
Amazon Bedrock User Guide.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"creationTimeAfter"`: Return customization jobs created after the specified time.
- `"creationTimeBefore"`: Return customization jobs created before the specified time.
- `"maxResults"`: The maximum number of results to return in the response. If the total
  number of results is greater than this value, use the token returned in the response in the
  nextToken field when making another request to return the next batch of results.
- `"nameContains"`: Return customization jobs only if the job name contains these
  characters.
- `"nextToken"`: If the total number of results is greater than the maxResults value
  provided in the request, enter the token returned in the nextToken field in the response in
  this field to return the next batch of results.
- `"sortBy"`: The field to sort by in the returned list of jobs.
- `"sortOrder"`: The sort order of the results.
- `"statusEquals"`: Return customization jobs with the specified status.
"""
list_model_customization_jobs(; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "GET",
        "/model-customization-jobs";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function list_model_customization_jobs(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/model-customization-jobs",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_model_import_jobs()
    list_model_import_jobs(params::Dict{String,<:Any})

Returns a list of import jobs you've submitted. You can filter the results to return based
on one or more criteria. For more information, see Import a customized model in the Amazon
Bedrock User Guide.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"creationTimeAfter"`: Return import jobs that were created after the specified time.
- `"creationTimeBefore"`: Return import jobs that were created before the specified time.
- `"maxResults"`: The maximum number of results to return in the response. If the total
  number of results is greater than this value, use the token returned in the response in the
  nextToken field when making another request to return the next batch of results.
- `"nameContains"`: Return imported jobs only if the job name contains these characters.
- `"nextToken"`: If the total number of results is greater than the maxResults value
  provided in the request, enter the token returned in the nextToken field in the response in
  this field to return the next batch of results.
- `"sortBy"`: The field to sort by in the returned list of imported jobs.
- `"sortOrder"`: Specifies whether to sort the results in ascending or descending order.
- `"statusEquals"`: Return imported jobs with the specified status.
"""
list_model_import_jobs(; aws_config::AbstractAWSConfig=current_aws_config()) = bedrock(
    "GET", "/model-import-jobs"; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET
)
function list_model_import_jobs(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/model-import-jobs",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_model_invocation_jobs()
    list_model_invocation_jobs(params::Dict{String,<:Any})

Lists all batch inference jobs in the account. For more information, see View details about
a batch inference job.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"maxResults"`: The maximum number of results to return. If there are more results than
  the number that you specify, a nextToken value is returned. Use the nextToken in a request
  to return the next batch of results.
- `"nameContains"`: Specify a string to filter for batch inference jobs whose names contain
  the string.
- `"nextToken"`: If there were more results than the value you specified in the maxResults
  field in a previous ListModelInvocationJobs request, the response would have returned a
  nextToken value. To see the next batch of results, send the nextToken value in another
  request.
- `"sortBy"`: An attribute by which to sort the results.
- `"sortOrder"`: Specifies whether to sort the results by ascending or descending order.
- `"statusEquals"`: Specify a status to filter for batch inference jobs whose statuses
  match the string you specify.
- `"submitTimeAfter"`: Specify a time to filter for batch inference jobs that were
  submitted after the time you specify.
- `"submitTimeBefore"`: Specify a time to filter for batch inference jobs that were
  submitted before the time you specify.
"""
list_model_invocation_jobs(; aws_config::AbstractAWSConfig=current_aws_config()) = bedrock(
    "GET",
    "/model-invocation-jobs";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function list_model_invocation_jobs(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/model-invocation-jobs",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_provisioned_model_throughputs()
    list_provisioned_model_throughputs(params::Dict{String,<:Any})

Lists the Provisioned Throughputs in the account. For more information, see Provisioned
Throughput in the Amazon Bedrock User Guide.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"creationTimeAfter"`: A filter that returns Provisioned Throughputs created after the
  specified time.
- `"creationTimeBefore"`: A filter that returns Provisioned Throughputs created before the
  specified time.
- `"maxResults"`: THe maximum number of results to return in the response. If there are
  more results than the number you specified, the response returns a nextToken value. To see
  the next batch of results, send the nextToken value in another list request.
- `"modelArnEquals"`: A filter that returns Provisioned Throughputs whose model Amazon
  Resource Name (ARN) is equal to the value that you specify.
- `"nameContains"`: A filter that returns Provisioned Throughputs if their name contains
  the expression that you specify.
- `"nextToken"`: If there are more results than the number you specified in the maxResults
  field, the response returns a nextToken value. To see the next batch of results, specify
  the nextToken value in this field.
- `"sortBy"`: The field by which to sort the returned list of Provisioned Throughputs.
- `"sortOrder"`: The sort order of the results.
- `"statusEquals"`: A filter that returns Provisioned Throughputs if their statuses matches
  the value that you specify.
"""
list_provisioned_model_throughputs(; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "GET",
        "/provisioned-model-throughputs";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function list_provisioned_model_throughputs(
    params::AbstractDict{String}; aws_config::AbstractAWSConfig=current_aws_config()
)
    return bedrock(
        "GET",
        "/provisioned-model-throughputs",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    list_tags_for_resource(resource_arn)
    list_tags_for_resource(resource_arn, params::Dict{String,<:Any})

List the tags associated with the specified resource. For more information, see Tagging
resources in the Amazon Bedrock User Guide.

# Arguments
- `resource_arn`: The Amazon Resource Name (ARN) of the resource.

"""
list_tags_for_resource(resourceARN; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "POST",
        "/listTagsForResource",
        Dict{String,Any}("resourceARN" => resourceARN);
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function list_tags_for_resource(
    resourceARN,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/listTagsForResource",
        Dict{String,Any}(
            mergewith(_merge, Dict{String,Any}("resourceARN" => resourceARN), params)
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    put_model_invocation_logging_configuration(logging_config)
    put_model_invocation_logging_configuration(logging_config, params::Dict{String,<:Any})

Set the configuration values for model invocation logging.

# Arguments
- `logging_config`: The logging configuration values to set.

"""
put_model_invocation_logging_configuration(
    loggingConfig; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "PUT",
    "/logging/modelinvocations",
    Dict{String,Any}("loggingConfig" => loggingConfig);
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function put_model_invocation_logging_configuration(
    loggingConfig,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "PUT",
        "/logging/modelinvocations",
        Dict{String,Any}(
            mergewith(_merge, Dict{String,Any}("loggingConfig" => loggingConfig), params)
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    stop_evaluation_job(job_identifier)
    stop_evaluation_job(job_identifier, params::Dict{String,<:Any})

Stops an in progress model evaluation job.

# Arguments
- `job_identifier`: The ARN of the model evaluation job you want to stop.

"""
stop_evaluation_job(jobIdentifier; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "POST",
        "/evaluation-job/$(jobIdentifier)/stop";
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function stop_evaluation_job(
    jobIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/evaluation-job/$(jobIdentifier)/stop",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    stop_model_customization_job(job_identifier)
    stop_model_customization_job(job_identifier, params::Dict{String,<:Any})

Stops an active model customization job. For more information, see Custom models in the
Amazon Bedrock User Guide.

# Arguments
- `job_identifier`: Job identifier of the job to stop.

"""
stop_model_customization_job(
    jobIdentifier; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "POST",
    "/model-customization-jobs/$(jobIdentifier)/stop";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function stop_model_customization_job(
    jobIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/model-customization-jobs/$(jobIdentifier)/stop",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    stop_model_invocation_job(job_identifier)
    stop_model_invocation_job(job_identifier, params::Dict{String,<:Any})

Stops a batch inference job. You're only charged for tokens that were already processed.
For more information, see Stop a batch inference job.

# Arguments
- `job_identifier`: The Amazon Resource Name (ARN) of the batch inference job to stop.

"""
stop_model_invocation_job(
    jobIdentifier; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "POST",
    "/model-invocation-job/$(jobIdentifier)/stop";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function stop_model_invocation_job(
    jobIdentifier,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/model-invocation-job/$(jobIdentifier)/stop",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    tag_resource(resource_arn, tags)
    tag_resource(resource_arn, tags, params::Dict{String,<:Any})

Associate tags with a resource. For more information, see Tagging resources in the Amazon
Bedrock User Guide.

# Arguments
- `resource_arn`: The Amazon Resource Name (ARN) of the resource to tag.
- `tags`: Tags to associate with the resource.

"""
tag_resource(resourceARN, tags; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "POST",
        "/tagResource",
        Dict{String,Any}("resourceARN" => resourceARN, "tags" => tags);
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function tag_resource(
    resourceARN,
    tags,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/tagResource",
        Dict{String,Any}(
            mergewith(
                _merge,
                Dict{String,Any}("resourceARN" => resourceARN, "tags" => tags),
                params,
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    untag_resource(resource_arn, tag_keys)
    untag_resource(resource_arn, tag_keys, params::Dict{String,<:Any})

Remove one or more tags from a resource. For more information, see Tagging resources in the
Amazon Bedrock User Guide.

# Arguments
- `resource_arn`: The Amazon Resource Name (ARN) of the resource to untag.
- `tag_keys`: Tag keys of the tags to remove from the resource.

"""
untag_resource(resourceARN, tagKeys; aws_config::AbstractAWSConfig=current_aws_config()) =
    bedrock(
        "POST",
        "/untagResource",
        Dict{String,Any}("resourceARN" => resourceARN, "tagKeys" => tagKeys);
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
function untag_resource(
    resourceARN,
    tagKeys,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "POST",
        "/untagResource",
        Dict{String,Any}(
            mergewith(
                _merge,
                Dict{String,Any}("resourceARN" => resourceARN, "tagKeys" => tagKeys),
                params,
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    update_guardrail(blocked_input_messaging, blocked_outputs_messaging, guardrail_identifier, name)
    update_guardrail(blocked_input_messaging, blocked_outputs_messaging, guardrail_identifier, name, params::Dict{String,<:Any})

Updates a guardrail with the values you specify.   Specify a name and optional description.
  Specify messages for when the guardrail successfully blocks a prompt or a model response
in the blockedInputMessaging and blockedOutputsMessaging fields.   Specify topics for the
guardrail to deny in the topicPolicyConfig object. Each GuardrailTopicConfig object in the
topicsConfig list pertains to one topic.   Give a name and description so that the
guardrail can properly identify the topic.   Specify DENY in the type field.   (Optional)
Provide up to five prompts that you would categorize as belonging to the topic in the
examples list.     Specify filter strengths for the harmful categories defined in Amazon
Bedrock in the contentPolicyConfig object. Each GuardrailContentFilterConfig object in the
filtersConfig list pertains to a harmful category. For more information, see Content
filters. For more information about the fields in a content filter, see
GuardrailContentFilterConfig.   Specify the category in the type field.   Specify the
strength of the filter for prompts in the inputStrength field and for model responses in
the strength field of the GuardrailContentFilterConfig.     (Optional) For security,
include the ARN of a KMS key in the kmsKeyId field.

# Arguments
- `blocked_input_messaging`: The message to return when the guardrail blocks a prompt.
- `blocked_outputs_messaging`: The message to return when the guardrail blocks a model
  response.
- `guardrail_identifier`: The unique identifier of the guardrail. This can be an ID or the
  ARN.
- `name`: A name for the guardrail.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"contentPolicyConfig"`: The content policy to configure for the guardrail.
- `"contextualGroundingPolicyConfig"`: The contextual grounding policy configuration used
  to update a guardrail.
- `"description"`: A description of the guardrail.
- `"kmsKeyId"`: The ARN of the KMS key with which to encrypt the guardrail.
- `"sensitiveInformationPolicyConfig"`: The sensitive information policy to configure for
  the guardrail.
- `"topicPolicyConfig"`: The topic policy to configure for the guardrail.
- `"wordPolicyConfig"`: The word policy to configure for the guardrail.
"""
update_guardrail(
    blockedInputMessaging,
    blockedOutputsMessaging,
    guardrailIdentifier,
    name;
    aws_config::AbstractAWSConfig=current_aws_config(),
) = bedrock(
    "PUT",
    "/guardrails/$(guardrailIdentifier)",
    Dict{String,Any}(
        "blockedInputMessaging" => blockedInputMessaging,
        "blockedOutputsMessaging" => blockedOutputsMessaging,
        "name" => name,
    );
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function update_guardrail(
    blockedInputMessaging,
    blockedOutputsMessaging,
    guardrailIdentifier,
    name,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "PUT",
        "/guardrails/$(guardrailIdentifier)",
        Dict{String,Any}(
            mergewith(
                _merge,
                Dict{String,Any}(
                    "blockedInputMessaging" => blockedInputMessaging,
                    "blockedOutputsMessaging" => blockedOutputsMessaging,
                    "name" => name,
                ),
                params,
            ),
        );
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end

"""
    update_provisioned_model_throughput(provisioned_model_id)
    update_provisioned_model_throughput(provisioned_model_id, params::Dict{String,<:Any})

Updates the name or associated model for a Provisioned Throughput. For more information,
see Provisioned Throughput in the Amazon Bedrock User Guide.

# Arguments
- `provisioned_model_id`: The Amazon Resource Name (ARN) or name of the Provisioned
  Throughput to update.

# Optional Parameters
Optional parameters can be passed as a `params::Dict{String,<:Any}`. Valid keys are:
- `"desiredModelId"`: The Amazon Resource Name (ARN) of the new model to associate with
  this Provisioned Throughput. You can't specify this field if this Provisioned Throughput is
  associated with a base model. If this Provisioned Throughput is associated with a custom
  model, you can specify one of the following options:   The base model from which the custom
  model was customized.   Another custom model that was customized from the same base model
  as the custom model.
- `"desiredProvisionedModelName"`: The new name for this Provisioned Throughput.
"""
update_provisioned_model_throughput(
    provisionedModelId; aws_config::AbstractAWSConfig=current_aws_config()
) = bedrock(
    "PATCH",
    "/provisioned-model-throughput/$(provisionedModelId)";
    aws_config=aws_config,
    feature_set=SERVICE_FEATURE_SET,
)
function update_provisioned_model_throughput(
    provisionedModelId,
    params::AbstractDict{String};
    aws_config::AbstractAWSConfig=current_aws_config(),
)
    return bedrock(
        "PATCH",
        "/provisioned-model-throughput/$(provisionedModelId)",
        params;
        aws_config=aws_config,
        feature_set=SERVICE_FEATURE_SET,
    )
end
